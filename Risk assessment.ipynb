{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbacb7d9",
   "metadata": {},
   "source": [
    "*About this notebook:* prepared for Ahead of the Storm Hackathon, UN, Open Source Week, 16-17 June 2025\n",
    "\n",
    "**Challenge 1: \n",
    "Unlocking Child-Centric Extreme Weather Intelligence: \n",
    "From Hindcasting to Forecasting, from Reaction to Proaction**\n",
    "\n",
    "Prepared by team **SAFE (Storm Action For EveryChild)**:\n",
    "\n",
    "Ngoc Tram Nguyen, Orsolya Horváth-Dudás, Rita Mateus, Shruthiveena Krishnamurthy,  Varvara Krechetova\n",
    "\n",
    "\n",
    "*Case Study: Bangladesh*\n",
    "\n",
    "The notebooks describes workflow, data and functions for identifying level of risks by risk domain and calculating number of affected children in given areas (flood risk zones, hurricane impact area, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e2df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import shape, Point\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.mask import mask\n",
    "from rasterstats import zonal_stats\n",
    "import folium\n",
    "import folium.raster_layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import branca.colormap as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845c8590",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Name: Bangladesh_Latest_-_Global_Administrative_Boundaries.zip\n",
    "# Description: Administrative boundaries, level 0, 1, 2, 3, and 4\n",
    "# Source: World Food Programme (WFP)\n",
    "# Format: geoJSON\n",
    "\n",
    "BGD_border_file = r\"C:\\UN Ahead of the storm Hackathon\\Adm_borders\\Bangladesh_Latest_-_Global_Administrative_Boundaries\\adm0.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flood Hazard 2 Years - SSP1 Lower bound\n",
    "# Source: https://giri.unepgrid.ch/map?list=explore\n",
    "# Id MX-V95CQ-75NRI-9BEHJ\n",
    "# Release date: Sun Apr 30 2023; Data value starting date: Sat Dec 31 2016; Data value ending date: Thu Dec 30 2100\n",
    "\n",
    "flood_risk_file = r\"C:\\UN Ahead of the storm Hackathon\\Flood_hurricane_weather\\global_rcp26_h2glob.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92afafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_raster_to_polygon(raster_path, shapefile_path, output_path, crop=True):\n",
    "    \"\"\"\n",
    "    Crop raster to polygon boundary using rasterio.mask\n",
    "    \n",
    "    Parameters:\n",
    "    - raster_path: path to input raster\n",
    "    - shapefile_path: path to polygon shapefile\n",
    "    - output_path: path for cropped raster output\n",
    "    - crop: if True, crop to polygon bounds; if False, just mask\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the shapefile\n",
    "    shapes_gdf = gpd.read_file(shapefile_path)\n",
    "    \n",
    "    # Read the raster\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Check if CRS match, reproject if needed\n",
    "        if shapes_gdf.crs != src.crs:\n",
    "            print(f\"Reprojecting shapefile from {shapes_gdf.crs} to {src.crs}\")\n",
    "            shapes_gdf = shapes_gdf.to_crs(src.crs)\n",
    "        \n",
    "        # Extract geometries\n",
    "        shapes = shapes_gdf.geometry.values\n",
    "        \n",
    "        # Crop the raster\n",
    "        out_image, out_transform = rasterio.mask.mask(\n",
    "            src, \n",
    "            shapes, \n",
    "            crop=crop,  # Crop to polygon bounds\n",
    "            nodata=src.nodata\n",
    "        )\n",
    "        \n",
    "        # Update metadata\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "    \n",
    "    # Write the cropped raster\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "    \n",
    "    print(f\"Raster cropped and saved to: {output_path}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768f0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster cropped and saved to: C:\\UN Ahead of the storm Hackathon\\Flood_hurricane_weather\\BGD_cropped_global_rcp26_h2glob.tif\n"
     ]
    }
   ],
   "source": [
    "# Cropped global Flood Hazard 2 Years - SSP1 Lower bound file to Bangladesh borders\n",
    "flood_risk_output_file = r\"C:\\UN Ahead of the storm Hackathon\\Flood_hurricane_weather\\BGD_cropped_global_rcp26_h2glob.tif\"\n",
    "flood_risk_BGD = crop_raster_to_polygon(flood_risk_file, BGD_border_file, flood_risk_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46bd00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Name: hotosm_bgd_health_facilities_points_geojson.geojson\n",
    "# Description: Points marking the location of health infrastructure in Bangladesh from OSM, including hospitals and clinics. Valuable for evaluating disaster impacts on essential services and emergency response capacity.\n",
    "# Source: https://data.humdata.org/dataset/hotosm_bgd_health_facilities\n",
    "# Format: GeoJSON\n",
    "\n",
    "\n",
    "# Clean the HOTOSM hospital file from pharmacies and dentist\n",
    "file_path = r'C:\\UN Ahead of the storm Hackathon\\Facilities\\hotosm_bgd_health_facilities_points_geojson.geojson'\n",
    "health_gdf = gpd.read_file(file_path)\n",
    "hospitals_doctors = health_gdf[health_gdf['amenity'].isin(['hospital', 'birthing_center', 'doctors', 'clinic'])]\n",
    "hospitals_doctors.to_file(r'C:\\UN Ahead of the storm Hackathon\\Facilities\\hotosm_bgd_health_facilities_points_cleaned.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78058818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 7798 entries, 0 to 7797\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   name              7222 non-null   object  \n",
      " 1   name:en           443 non-null    object  \n",
      " 2   amenity           7696 non-null   object  \n",
      " 3   building          307 non-null    object  \n",
      " 4   operator:type     127 non-null    object  \n",
      " 5   capacity:persons  55 non-null     object  \n",
      " 6   addr:full         4 non-null      object  \n",
      " 7   addr:city         665 non-null    object  \n",
      " 8   source            1351 non-null   object  \n",
      " 9   name:bn           260 non-null    object  \n",
      " 10  osm_id            7798 non-null   int64   \n",
      " 11  osm_type          7798 non-null   object  \n",
      " 12  geometry          7798 non-null   geometry\n",
      "dtypes: geometry(1), int64(1), object(11)\n",
      "memory usage: 792.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['school', 'college', 'university', 'kindergarten', None,\n",
       "       'marketplace'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File Name: hotosm_bgd_education_facilities_points_geojson.geojson\n",
    "# Description: Geolocated point dataset of educational facilities (schools, colleges, etc.) from OSM in Bangladesh. Useful for identifying critical public infrastructure and assessing their disaster exposure or accessibility.\n",
    "# Source: https://data.humdata.org/dataset/hotosm_bgd_education_facilities\n",
    "# Format: GeoJSON\n",
    "\n",
    "# Clean the HOTOSM school file \n",
    "file_path_sch = r'C:\\UN Ahead of the storm Hackathon\\Facilities\\hotosm_bgd_education_facilities_points_geojson.geojson'\n",
    "school_gdf = gpd.read_file(file_path_sch)\n",
    "school_gdf.info()\n",
    "school_gdf['amenity'].unique()\n",
    "schools = school_gdf[school_gdf['amenity'].isin(['school', 'college', 'university', 'kindergarten'])]\n",
    "schools.to_file(r'C:\\UN Ahead of the storm Hackathon\\Facilities\\hotosm_bgd_education_facilities_points_cleaned.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f66939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Bangladesh district borders to poverty data from \"POVERTY MAPS OF BANGLADESH 2016\" December 2020, Dhaka. \n",
    "# https://bbs.portal.gov.bd/sites/default/files/files/bbs.portal.gov.bd/page/5695ab85_1403_483a_afb4_26dfd767df18/2021-02-22-16-57-c64fb3d272175e7efea0b02de6a23eaa.pdf\n",
    "\n",
    "bgd_adm2_polygons = r\"C:\\UN Ahead of the storm Hackathon\\Adm_borders\\Bangladesh_Latest_-_Global_Administrative_Boundaries\\adm2.geojson\"\n",
    "poverty_data = r\"C:\\UN Ahead of the storm Hackathon\\soc-ec\\HCR_povertyrate_district.xlsx\"\n",
    "\n",
    "bgd_adm2_gdf = gpd.read_file(bgd_adm2_polygons)\n",
    "poverty_df = pd.read_excel(poverty_data)\n",
    "\n",
    "# Merge the data based on a common column\n",
    "bgd_adm2_poverty_gdf = bgd_adm2_gdf.merge(poverty_df,\n",
    "                                          left_on='name', \n",
    "                                          right_on='District',\n",
    "                                          how='left')\n",
    "bgd_adm2_poverty_gdf.to_file(r\"C:\\UN Ahead of the storm Hackathon\\Adm_borders\\Bangladesh_Latest_-_Global_Administrative_Boundaries\\adm2_pov.geojson\")\n",
    "# The missing values from merging issues were inputted manually in QGIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81108c",
   "metadata": {},
   "source": [
    "## Risk analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819ca387",
   "metadata": {},
   "source": [
    "#### Identify flood risk zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22fe8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_classified_polygons(raster_path, output_path, method='quantile'):\n",
    "    \"\"\"\n",
    "    Classify raster into 3 groups and convert to vector polygons\n",
    "    \n",
    "    Parameters:\n",
    "    - raster_path: path to input raster file\n",
    "    - output_path: path for output shapefile\n",
    "    - method: 'quantile', 'equal_interval', or 'manual'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the raster\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_data = src.read(1)  # Read first band\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        nodata = src.nodata\n",
    "    \n",
    "    # Mask nodata values\n",
    "    if nodata is not None:\n",
    "        valid_mask = raster_data != nodata\n",
    "        valid_data = raster_data[valid_mask]\n",
    "    else:\n",
    "        valid_data = raster_data.flatten()\n",
    "        valid_mask = np.ones_like(raster_data, dtype=bool)\n",
    "    \n",
    "    # Create classification based on method\n",
    "    if method == 'quantile':\n",
    "        # Use 33rd and 67th percentiles\n",
    "        thresholds = np.percentile(valid_data, [33.33, 66.67])\n",
    "    elif method == 'equal_interval':\n",
    "        # Equal intervals between min and max\n",
    "        min_val, max_val = np.min(valid_data), np.max(valid_data)\n",
    "        interval = (max_val - min_val) / 3\n",
    "        thresholds = [min_val + interval, min_val + 2*interval]\n",
    "    else:\n",
    "        # Manual thresholds - adjust these values as needed\n",
    "        thresholds = [np.percentile(valid_data, 33), np.percentile(valid_data, 67)]\n",
    "    \n",
    "    # Create classified raster\n",
    "    classified = np.zeros_like(raster_data, dtype=np.int32)\n",
    "    \n",
    "    # Assign classes: 1 (low), 2 (medium), 3 (high)\n",
    "    classified[raster_data <= thresholds[0]] = 1\n",
    "    classified[(raster_data > thresholds[0]) & (raster_data <= thresholds[1])] = 2\n",
    "    classified[raster_data > thresholds[1]] = 3\n",
    "    \n",
    "    # Set nodata areas to 0\n",
    "    if nodata is not None:\n",
    "        classified[~valid_mask] = 0\n",
    "    \n",
    "    # Convert to polygons\n",
    "    polygons = []\n",
    "    values = []\n",
    "    \n",
    "    # Extract shapes for each class\n",
    "    for class_val in [1, 2, 3]:\n",
    "        mask = classified == class_val\n",
    "        for geom, val in shapes(mask.astype(np.uint8), transform=transform):\n",
    "            if val == 1:  # Only keep polygons where mask is True\n",
    "                polygons.append(shape(geom))\n",
    "                values.append(class_val)\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame({\n",
    "        'class': values,\n",
    "        'geometry': polygons\n",
    "    }, crs=crs)\n",
    "    \n",
    "    # Add descriptive labels\n",
    "    class_labels = {1: 'Low', 2: 'Medium', 3: 'High'}\n",
    "    gdf['label'] = gdf['class'].map(class_labels)\n",
    "    \n",
    "    # Save to shapefile\n",
    "    gdf.to_file(output_path)\n",
    "    \n",
    "    print(f\"Classification thresholds: {thresholds}\")\n",
    "    print(f\"Number of polygons created: {len(gdf)}\")\n",
    "    print(f\"Polygons saved to: {output_path}\")\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification thresholds: [115. 274.]\n",
      "Number of polygons created: 343698\n",
      "Polygons saved to: C:\\UN Ahead of the storm Hackathon\\Risk files\\flood_risk_zones.shp\n",
      "\n",
      "Class distribution:\n",
      "class\n",
      "1    167449\n",
      "2    134308\n",
      "3     41941\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting risk zones for foolds based on the Flood Hazard 2 Years - SSP1 Lower bound estimates\n",
    "raster_file = flood_risk_BGD\n",
    "output_file = r\"C:\\UN Ahead of the storm Hackathon\\Risk files\\flood_risk_zones.shp\"\n",
    "\n",
    "gdf = raster_to_classified_polygons(raster_file, output_file, method='quantile')\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nClass distribution:\")\n",
    "print(gdf['class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395355d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_zones_flood_gdf = gpd.read_file(r'C:\\UN Ahead of the storm Hackathon\\Risk files\\flood_risk_zones.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c4235",
   "metadata": {},
   "source": [
    "#### Identify poverty rates tresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgd_adm2_poverty_gdf_cleaned = gpd.read_file(r'C:\\UN Ahead of the storm Hackathon\\soc-ec\\adm2_pov.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816b228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value70.8\n",
      "min_value2.6\n"
     ]
    }
   ],
   "source": [
    "bgd_adm2_poverty_gdf_cleaned['HCR Upper(%)']\n",
    "min_value =bgd_adm2_poverty_gdf_cleaned['HCR Upper(%)'].min()\n",
    "max_value = bgd_adm2_poverty_gdf_cleaned['HCR Upper(%)'].max()\n",
    "print(f'max value{max_value}')\n",
    "print(f'min_value{min_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2237fce",
   "metadata": {},
   "source": [
    "The treshold identified and original plan was to correct the risk assessments for other types of risks based on them, however, time was not enough, but this can be done in future.\n",
    "\n",
    "\n",
    "- below 10% - do not change risk class\n",
    "- 10 - 50% - up risk assessment 1 level\n",
    "- over 50% - up  risk assessment 2 levels or leave high risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10a913",
   "metadata": {},
   "source": [
    "### Making risk zones maps for schooling and medial services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffb0d5",
   "metadata": {},
   "source": [
    "**Workflow for creating isodistance lines from hospitals and schools:**\n",
    "\n",
    "Ideally:\n",
    "1) The projection should be changed projected cooordinate system to measure distances in meters\n",
    "2) Network analysis in QGIS/ArcGIS/PostGIS should be used.\n",
    "\n",
    "We worked in QGIS.\n",
    "Due to lack of time to, mostly, work through the OSM line features to connect all the line features for the analysis and to additional operations, quick workaround is used:\n",
    "\n",
    "1) Draw buffer zones in 0.05 degree (about 5.5 km) and 0.1 degree (about 11 km) around the hospitals (Vector -> Geoprocessing tools -> Buffer)\n",
    "2) Dissolve each layer, so overlapping buffers merge (Vector -> Geoprocessing tools -> Dissolve)\n",
    "3) Make difference polygons between buffer 0.1 degree and buffer 0.05 degree\n",
    "4) Add buffer 0.05 degree polygons and the difference polygons into one shapefile (Medical_assistance_risk.shp).\n",
    "4) Make difference polygons between Bangladesh state border and Medical_assistance_risk.shp polygons.\n",
    "5) Add the difference polygons into the Medical_assistance_risk.shp\n",
    "6) Take the Intersection between the Bangladesh state border and Medical_assistance_risk.shp polygons to get rid of the areas outside the state border.\n",
    "\n",
    "For the schools the processing is the same except the risk zones are narrower: 0.01 degree (~1 km) and 0.05 (~5 km) degree.\n",
    "\n",
    "The resulting zoning is used for mining data below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323236d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99f27c8f",
   "metadata": {},
   "source": [
    "## Using the risk assesment to mine data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d425ee7",
   "metadata": {},
   "source": [
    "### Calculate number of children affected by an event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6008c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files with risk classifications after QGIS step:\n",
    "schooling_risk_gdf = gpd.read_file(r\"C:\\UN Ahead of the storm Hackathon\\Risk files\\Schools_attendance_risk_cr.shp\")\n",
    "medical_risk_gdp = gpd.read_file(r\"C:\\UN Ahead of the storm Hackathon\\Risk files\\Medical_assistance_risk_cr.shp\")\n",
    "# # Other files for risk assessments (repeating from above)\n",
    "bgd_adm2_poverty_gdf_cleaned = gpd.read_file(r'C:\\UN Ahead of the storm Hackathon\\soc-ec\\adm2_pov.geojson')\n",
    "risk_zones_flood_gdf = gpd.read_file(r'C:\\UN Ahead of the storm Hackathon\\Risk files\\flood_risk_zones.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a74ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bgd_f_0_2020_constrained_UNadj.tif',\n",
       " 'bgd_f_10_2020_constrained_UNadj.tif',\n",
       " 'bgd_f_15_2020_constrained_UNadj.tif',\n",
       " 'bgd_f_1_2020_constrained_UNadj.tif',\n",
       " 'bgd_f_5_2020_constrained_UNadj.tif',\n",
       " 'BGD_kids_10-15_total.tif',\n",
       " 'BGD_kids_5-10_total.tif',\n",
       " 'BGD_kids_under_5_total.tif',\n",
       " 'bgd_m_0_2020_constrained_UNadj.tif',\n",
       " 'bgd_m_10_2020_constrained_UNadj.tif',\n",
       " 'bgd_m_15_2020_constrained_UNadj.tif',\n",
       " 'bgd_m_1_2020_constrained_UNadj.tif',\n",
       " 'bgd_m_5_2020_constrained_UNadj.tif']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From WorldPop Bangladesh age structures:\n",
    "# https://hub.worldpop.org/geodata/summary?id=50363\n",
    "\n",
    "# Files with children population\n",
    "population_dir = os.path.join('.', 'Population')\n",
    "tif_files_pop = [f for f in os.listdir(population_dir) if f.endswith('.tif')]\n",
    "tif_files_pop\n",
    "\n",
    "# ['bgd_f_0_2020_constrained_UNadj.tif', # girls under 1 year old\n",
    "#  'bgd_f_10_2020_constrained_UNadj.tif', # girls ages 10-15\n",
    "#  'bgd_f_15_2020_constrained_UNadj.tif', # same naming convention \n",
    "#  'bgd_f_1_2020_constrained_UNadj.tif',\n",
    "#  'bgd_f_5_2020_constrained_UNadj.tif',\n",
    "#  'BGD_kids_10-15_total.tif', # preprocessed by merging boys and girls data\n",
    "#  'BGD_kids_5-10_total.tif', # preprocessed by merging boys and girls data\n",
    "#  'BGD_kids_under_5_total.tif', # preprocessed by merging boys and girls data\n",
    "#  'bgd_m_0_2020_constrained_UNadj.tif', # boys under 1 year old\n",
    "#  'bgd_m_10_2020_constrained_UNadj.tif', # boys ages 10-15\n",
    "#  'bgd_m_15_2020_constrained_UNadj.tif', # same naming convention \n",
    "#  'bgd_m_1_2020_constrained_UNadj.tif',\n",
    "#  'bgd_m_5_2020_constrained_UNadj.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd55a2",
   "metadata": {},
   "source": [
    "### Calculate number of kids that can lose schooling in case of catastrophic event overall in Bangladesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c3c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children between 5 and 10 in Low risk of losing schooling days: 3,766,931\n",
      "Children between 5 and 10 in Medium risk of losing schooling days: 5,893,504\n",
      "Children between 5 and 10 in High risk of losing schooling days: 4,580,140\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of children that can lose schooling in case of catastrophic event overall in Bangladesh\n",
    "\n",
    "selected_file = 'BGD_kids_5-10_total.tif'\n",
    "file_path = os.path.join(population_dir, selected_file)\n",
    "stats_sums = zonal_stats(schooling_risk_gdf, file_path, stats = ['sum'])\n",
    "for i, (class_name, stat_sum) in enumerate(zip(schooling_risk_gdf['Label'], stats_sums)):\n",
    "    print(f\"Children between 5 and 10 in {class_name} risk of losing schooling days: {stat_sum['sum']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b3326",
   "metadata": {},
   "source": [
    "### Calculate how many kids under 5 that live in high flood risk zones also are high risk of not getting medical assistance in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ebfa2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate how many children under 5 that live in high flood risk zones also are high risk of not getting medical assistance in time\n",
    "\n",
    "## From the raster with number of children under 5 per grid cell select those that are in high risk of flooding\n",
    "\n",
    "high_risk_flood_areas = risk_zones_flood_gdf[risk_zones_flood_gdf['class'] == 3]\n",
    "selected_file = 'BGD_kids_under_5_total.tif'\n",
    "input_raster = os.path.join(population_dir, selected_file)\n",
    "with rasterio.open(input_raster) as src:\n",
    "    # Extract geometries for masking\n",
    "    geometries = high_risk_flood_areas.geometry.values\n",
    "    \n",
    "    # Mask raster with Class 3 polygons\n",
    "    masked_data, transform = mask(src, geometries, crop=True, nodata=src.nodata)\n",
    "    \n",
    "    # Update metadata for output\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": masked_data.shape[1],\n",
    "        \"width\": masked_data.shape[2],\n",
    "        \"transform\": transform,\n",
    "        \"nodata\": src.nodata\n",
    "    })\n",
    "    \n",
    "    # Save masked raster\n",
    "    with rasterio.open('high_risk_flood_kids_under_5.tif', 'w', **out_meta) as dest:\n",
    "        dest.write(masked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15f25469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children under 5 living in high flood risk zones also in Low risk of not getting timely medical services: 388,422\n",
      "Children under 5 living in high flood risk zones also in Medium risk of not getting timely medical services: 343,367\n",
      "Children under 5 living in high flood risk zones also in High risk of not getting timely medical services: 141,325\n"
     ]
    }
   ],
   "source": [
    "## Calculate number of those children also in high medical risk areas\n",
    "\n",
    "selected_file = 'high_risk_flood_kids_under_5.tif'\n",
    "# file_path = os.path.join(population_dir, selected_file)\n",
    "stats_sums = zonal_stats(medical_risk_gdp, selected_file, stats = ['sum'])\n",
    "for i, (class_name, stat_sum) in enumerate(zip(medical_risk_gdp['Label'], stats_sums)):\n",
    "    print(f\"Children under 5 living in high flood risk zones also in {class_name} risk of not getting timely medical services: {stat_sum['sum']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f589c0",
   "metadata": {},
   "source": [
    "### Calculate how many kids under 5 that live in high poverty areas  also are high flood risk zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c26f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate how many children under 5 that live in high poverty areas also are in high flood risk zones\n",
    "\n",
    "## From the raster with number of children under 5 per grid cell select those that are in high poverty areas\n",
    "\n",
    "high_povety_areas = bgd_adm2_poverty_gdf_cleaned[bgd_adm2_poverty_gdf_cleaned['HCR Upper(%)'] > 50]\n",
    "selected_file = 'BGD_kids_under_5_total.tif'\n",
    "input_raster = os.path.join(population_dir, selected_file)\n",
    "with rasterio.open(input_raster) as src:\n",
    "    # Extract geometries for masking\n",
    "    geometries = high_povety_areas.geometry.values\n",
    "    \n",
    "    # Mask raster with Class 3 polygons\n",
    "    masked_data, transform = mask(src, geometries, crop=True, nodata=src.nodata)\n",
    "    \n",
    "    # Update metadata for output\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": masked_data.shape[1],\n",
    "        \"width\": masked_data.shape[2],\n",
    "        \"transform\": transform,\n",
    "        \"nodata\": src.nodata\n",
    "    })\n",
    "    \n",
    "    # Save masked raster\n",
    "    with rasterio.open('high_povety_areas_kids_under_5.tif', 'w', **out_meta) as dest:\n",
    "        dest.write(masked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87663067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary by flood risk level:\n",
      "High risk: 82,093 children\n",
      "\n",
      "Total children in all flood risk areas: 82,093\n"
     ]
    }
   ],
   "source": [
    "## Calculate number of those children also in high flood risk areas\n",
    "\n",
    "selected_file = 'high_povety_areas_kids_under_5.tif'\n",
    "stats_sums = zonal_stats(high_risk_flood_areas, selected_file, stats=['sum'])\n",
    "\n",
    "# Create a DataFrame for easier grouping\n",
    "df = pd.DataFrame({\n",
    "    'label': high_risk_flood_areas['label'],\n",
    "    'count': [stat['sum'] if stat['sum'] is not None else 0 for stat in stats_sums]\n",
    "})\n",
    "\n",
    "# Group by label and sum\n",
    "summary = df.groupby('label')['count'].sum()\n",
    "\n",
    "print(\"Summary by flood risk level:\")\n",
    "for risk_level, total_count in summary.items():\n",
    "    print(f\"{risk_level} risk: {total_count:,.0f} children\")\n",
    "\n",
    "print(f\"\\nTotal children under 5 in all flood risk areas: {summary.sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99314b",
   "metadata": {},
   "source": [
    "### Analysing risks along the high impact zone on the Ampan track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef229c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Schools_attendance_risk_cr.shp\n",
      "Saved: Schools_attendance_risk_cr_cropped.shp (3 features)\n",
      "Processing: Medical_assistance_risk_cr.shp\n",
      "Saved: Medical_assistance_risk_cr_cropped.shp (3 features)\n",
      "Processing: flood_risk_zones.shp\n",
      "Saved: flood_risk_zones_cropped.shp (16168 features)\n",
      "Processing: adm2_poverty.shp\n",
      "Saved: adm2_poverty_cropped.shp (10 features)\n"
     ]
    }
   ],
   "source": [
    "# Creating the risk assessment files for only the impact area\n",
    "\n",
    "risk_files = [\n",
    "    'Schools_attendance_risk_cr.shp',\n",
    "    'Medical_assistance_risk_cr.shp',\n",
    "    'flood_risk_zones.shp',\n",
    "    'adm2_poverty.shp'\n",
    "]\n",
    "\n",
    "clip_geom = r'C:\\UN Ahead of the storm Hackathon\\Flood_hurricane_weather\\amphan_high_impact_zone.shp'\n",
    "f_folder = r\"C:\\UN Ahead of the storm Hackathon\\Risk files\"\n",
    "output_folder = r\"C:\\UN Ahead of the storm Hackathon\\Risk files\\Clipped_outputs\"  # Optional: specify output folder\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read clip boundary once (more efficient)\n",
    "clip_boundary = gpd.read_file(clip_geom)\n",
    "\n",
    "for f in risk_files:\n",
    "    try:\n",
    "        # Read the shapefile\n",
    "        f_path = os.path.join(f_folder, f)\n",
    "        polygons = gpd.read_file(f_path)\n",
    "        \n",
    "        print(f\"Processing: {f}\")\n",
    "        \n",
    "        # Ensure both have the same CRS\n",
    "        if polygons.crs != clip_boundary.crs:\n",
    "            clip_boundary_proj = clip_boundary.to_crs(polygons.crs)\n",
    "        else:\n",
    "            clip_boundary_proj = clip_boundary\n",
    "        \n",
    "        # Clip the polygons\n",
    "        clipped = gpd.clip(polygons, clip_boundary_proj)\n",
    "        \n",
    "        # Create output filename and path\n",
    "        output_name = f.replace('.shp', '_cropped.shp')\n",
    "        output_path = os.path.join(output_folder, output_name)\n",
    "        \n",
    "        # Save the result\n",
    "        clipped.to_file(output_path)\n",
    "        \n",
    "        print(f\"Saved: {output_name} ({len(clipped)} features)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {f}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ab319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schooling_risk_am_gdf = gpd.read_file(r\"C:\\UN Ahead of the storm Hackathon\\Risk files\\Clipped_outputs\\Schools_attendance_risk_cr_cropped.shp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c24f63",
   "metadata": {},
   "source": [
    "### Calculate number of kids with schooling at risk due to Amphan impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de54f06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children BGD_kids_10-15_total.tif in Low risk of losing schooling days: 141,339\n",
      "Children BGD_kids_10-15_total.tif in Medium risk of losing schooling days: 271,154\n",
      "Children BGD_kids_10-15_total.tif in High risk of losing schooling days: 153,239\n",
      "Children BGD_kids_5-10_total.tif in Low risk of losing schooling days: 142,453\n",
      "Children BGD_kids_5-10_total.tif in Medium risk of losing schooling days: 274,928\n",
      "Children BGD_kids_5-10_total.tif in High risk of losing schooling days: 153,521\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of children with schooling at risk\n",
    "files_pop = [\n",
    "    'BGD_kids_10-15_total.tif',\n",
    "    'BGD_kids_5-10_total.tif',\n",
    "]\n",
    "\n",
    "for f_pop in files_pop:\n",
    "\n",
    "    file_path = os.path.join(population_dir, f_pop)\n",
    "    stats_sums = zonal_stats(schooling_risk_am_gdf, file_path, stats = ['sum'])\n",
    "    for i, (class_name, stat_sum) in enumerate(zip(schooling_risk_am_gdf['Label'], stats_sums)):\n",
    "        print(f\"Children {f_pop} in {class_name} risk of losing schooling days: {stat_sum['sum']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf5c43a",
   "metadata": {},
   "source": [
    "### Calculate number of kids under 5 in high poverty areas and at risk of loosing medical services due to Amphan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25bcc5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 high poverty areas\n",
      "Successfully saved masked raster: C:\\UN Ahead of the storm Hackathon\\Outputs\\high_poverty_areas_kids_under_5_am.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read poverty data\n",
    "poverty_am_gdf = gpd.read_file(r\"C:\\UN Ahead of the storm Hackathon\\Risk files\\Clipped_outputs\\adm2_poverty_cropped.shp\")\n",
    "\n",
    "# Filter high poverty areas (fixed typo: povety -> poverty)\n",
    "high_poverty_areas_am = poverty_am_gdf[poverty_am_gdf['HCR Upper('] > 50]\n",
    "\n",
    "# Check if any high poverty areas exist\n",
    "if len(high_poverty_areas_am) == 0:\n",
    "    print(\"No areas found with poverty rate > 50%\")\n",
    "else:\n",
    "    print(f\"Found {len(high_poverty_areas_am)} high poverty areas\")\n",
    "\n",
    "    selected_file = 'BGD_kids_under_5_total.tif'\n",
    "    input_raster = os.path.join(population_dir, selected_file)\n",
    "    \n",
    "    # Check if input raster exists\n",
    "    if not os.path.exists(input_raster):\n",
    "        print(f\"Error: Raster file not found: {input_raster}\")\n",
    "    else:\n",
    "        try:\n",
    "            with rasterio.open(input_raster) as src:\n",
    "                # Ensure CRS alignment\n",
    "                if high_poverty_areas_am.crs != src.crs:\n",
    "                    high_poverty_areas_am = high_poverty_areas_am.to_crs(src.crs)\n",
    "                \n",
    "                # Extract geometries for masking\n",
    "                geometries = high_poverty_areas_am.geometry.values\n",
    "                \n",
    "                # Mask raster with high poverty polygons\n",
    "                masked_data, transform = mask(src, geometries, crop=True, nodata=src.nodata)\n",
    "                \n",
    "                # Update metadata for output\n",
    "                out_meta = src.meta.copy()\n",
    "                out_meta.update({\n",
    "                    \"driver\": \"GTiff\",\n",
    "                    \"height\": masked_data.shape[1],\n",
    "                    \"width\": masked_data.shape[2],\n",
    "                    \"transform\": transform,\n",
    "                    \"nodata\": src.nodata\n",
    "                })\n",
    "                \n",
    "                # Create output path\n",
    "                output_path = r\"C:\\UN Ahead of the storm Hackathon\\Outputs\\high_poverty_areas_kids_under_5_am.tif\"\n",
    "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "                \n",
    "                # Save masked raster\n",
    "                with rasterio.open(output_path, 'w', **out_meta) as dest:\n",
    "                    dest.write(masked_data)\n",
    "                \n",
    "                print(f\"Successfully saved masked raster: {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing raster: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c729d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children under 5 living in high poverty areas also in Low risk of not getting timely medical services due to Amphan: 43,199\n",
      "Children under 5 living in high poverty areas also in Medium risk of not getting timely medical services due to Amphan: 43,400\n",
      "Children under 5 living in high poverty areas also in High risk of not getting timely medical services due to Amphan: 9,651\n"
     ]
    }
   ],
   "source": [
    "## Calculate number of those children also in high medical risk areas\n",
    "medical_risk_gdf_am = gpd.read_file(r'C:\\UN Ahead of the storm Hackathon\\Risk files\\Clipped_outputs\\Medical_assistance_risk_cr_cropped.shp')\n",
    "selected_file = r'C:\\UN Ahead of the storm Hackathon\\Outputs\\high_poverty_areas_kids_under_5_am.tif'\n",
    "stats_sums = zonal_stats(medical_risk_gdf_am, selected_file, stats = ['sum'])\n",
    "for i, (class_name, stat_sum) in enumerate(zip(medical_risk_gdf_am['Label'], stats_sums)):\n",
    "    print(f\"Children under 5 living in high poverty areas also in {class_name} risk of not getting timely medical services due to Amphan: {stat_sum['sum']:,.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "un_storm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
